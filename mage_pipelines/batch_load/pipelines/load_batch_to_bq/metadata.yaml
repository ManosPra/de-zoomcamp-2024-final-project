blocks:
- all_upstream_blocks_executed: true
  color: null
  configuration: {}
  downstream_blocks:
  - quality_checks
  executor_config: null
  executor_type: local_python
  has_callback: null
  language: python
  name: generate_data
  retry_config:
    delay: 5
    retries: 3
  status: executed
  timeout: null
  type: data_loader
  upstream_blocks: []
  uuid: generate_data
- all_upstream_blocks_executed: true
  color: null
  configuration: {}
  downstream_blocks:
  - export_to_gbq
  executor_config: null
  executor_type: local_python
  has_callback: null
  language: python
  name: quality_checks
  retry_config:
    delay: 5
    retries: 3
  status: executed
  timeout: null
  type: transformer
  upstream_blocks:
  - generate_data
  uuid: quality_checks
- all_upstream_blocks_executed: true
  color: null
  configuration: {}
  downstream_blocks: []
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: export_to_gbq
  retry_config:
    delay: 5
    retries: 3
  status: executed
  timeout: null
  type: data_exporter
  upstream_blocks:
  - quality_checks
  uuid: export_to_gbq
cache_block_output_in_memory: false
callbacks: []
concurrency_config: {}
conditionals: []
created_at: null
data_integration: null
description: Generate synthetic data and load to big query
executor_config: {}
executor_count: 1
executor_type: null
extensions: {}
name: load_batch_to_bq
notification_config: {}
remote_variables_dir: null
retry_config: {}
run_pipeline_in_one_process: false
settings:
  triggers: null
spark_config: {}
tags: []
type: python
uuid: load_batch_to_bq
variables_dir: /home/src/mage_data/default_repo
widgets: []
